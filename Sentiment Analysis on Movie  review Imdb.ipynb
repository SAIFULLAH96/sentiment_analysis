{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "843fe996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy #for nltk\n",
    "import string # for text\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer # for Word2vec\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC # since its classification, could also use logistic also and other classification algotihm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9a7ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/Users/syedsaifullahtarique/Desktop/Work/Nados-Pepcoding/NLP/sentiment-analysis-on-movie-reviews/IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adf17f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b4a0e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a13aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an object \n",
    "nlp = English()\n",
    "#Creating list of stopwords\n",
    "stopwords = list(STOP_WORDS)\n",
    "# Creating list of punctuations\n",
    "punctuations = string.punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfabf08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "def tokenizer(sentence):\n",
    "    mytokens = nlp(sentence)\n",
    "    # Note that spaCy uses '-PRON-' as lemma for all personal pronouns lkike me, I etc\n",
    "    mytokens = [word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens]\n",
    "    mytokens = [word for word in mytokens if word not in stopwords and word not in punctuations]\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee33ec",
   "metadata": {},
   "source": [
    "- We will create custom transformer to clean the tokenized data\n",
    "- We will create a custom predictors class which inherits the TransformerMixin class. This class overrides the transform, fit and get_parrams methods. Weâ€™ll also create a clean_text() function that removes spaces and converts text into lowercase.\n",
    "- In object-oriented programming languages, a mixin (or mix-in) is a class that contains methods for use by other classes without having to be the parent class of those other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1679d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation (basically cleaning the text)  lower the text but not convert US to us\n",
    "class predictors(TransformerMixin):\n",
    "    def transform(self,X, **transform_params):\n",
    "         return [clean_text(text) for text in X]\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "    def get_params(self, deep = True):\n",
    "        return()\n",
    "# Basic function to clean the text\n",
    "def clean_text(text):\n",
    "    return text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d88f07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer = tokenizer,ngram_range=(1,1))\n",
    "tfvectorizer = TfidfVectorizer(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2632bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25000\n",
       "0    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label encode y\n",
    "le = preprocessing.LabelEncoder()\n",
    "dataset['sentiment'] = le.fit_transform(dataset['sentiment'])\n",
    "#dataset.rename({'positive':1,'negative':0},inplace = True)\n",
    "dataset['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ed240dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset\n",
    "X = dataset['review']\n",
    "y = dataset['sentiment']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4bcffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c2236320",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "SVCclassifier = LinearSVC()\n",
    "SVCmodel = Pipeline([('cleaner',predictors()),\n",
    "                     ('vectorizer',vectorizer),\n",
    "                    ('classifier',SVCclassifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f47628f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  ConvergenceWarning,\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "SVCmodel.fit(X_train,y_train)\n",
    "SVCpre = SVCmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e623492a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4271,  690],\n",
       "       [ 659, 4380]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluation\n",
    "confusion_matrix(y_test,SVCpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b3f2ed30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8651"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,SVCpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df9b4da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86      4961\n",
      "           1       0.86      0.87      0.87      5039\n",
      "\n",
      "    accuracy                           0.87     10000\n",
      "   macro avg       0.87      0.87      0.87     10000\n",
      "weighted avg       0.87      0.87      0.87     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,SVCpre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4a2659fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  1\n"
     ]
    }
   ],
   "source": [
    "pre = SVCmodel.predict(['It was very good'])\n",
    "print(\"prediction: \",pre[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "282dd10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction:  0\n"
     ]
    }
   ],
   "source": [
    "pre = SVCmodel.predict(['It was horrible.. wanted to leave in the middle'])\n",
    "print(\"prediction: \",pre[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5416f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
